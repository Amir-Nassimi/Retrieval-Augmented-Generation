{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38530144-2630-441a-8021-8d6cf1f67f26",
   "metadata": {},
   "source": [
    "# Read ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b516dd-a2d3-4397-8393-7eeba4d0b784",
   "metadata": {},
   "source": [
    "GPT-2 XL is the 1.5B parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective. s.\n",
    "\n",
    "You can also use gpt2-medium, gpt2-large, gpts.2-xl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae5b38-1884-4713-bbb8-3da9171b032d",
   "metadata": {},
   "source": [
    "Here are some secondary use cases we believe are likely:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3d7d3-3468-409d-bdd7-1f794aeba8a7",
   "metadata": {},
   "source": [
    "1- Writing assistance: Grammar assistance, autocompletionon (for normal prose or cod)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b26bc-99ed-4aac-874e-0515b9c3e76f",
   "metadata": {},
   "source": [
    "2- Creative writing and art: exploring the generation of creative, fictional texts; aiding creation of poetry and other literary art. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388d876-778b-45a9-b23e-e780428df17f",
   "metadata": {},
   "source": [
    "3- Entertainment: Creation of games, chat bots, and amusing generations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f701dc-6eca-48a6-8e22-3cc5c028f1a1",
   "metadata": {},
   "source": [
    "Because large-scale language models like GPT-2 do not distinguish fact from fiction, we donâ€™t support use-cases that require the generated text to be true.\n",
    "\n",
    "Additionally, language models like GPT-2 reflect the biases inherent to the systems they were trained on, so we do not recommend that they be deployed into systems that interact with humans unless the deployers first carry out a study of biases relevant to the intended use-case. We found no statistically significant difference in gender, race, and religious bias probes between 774M and 1.5B, implying all versions of GPT-2 should be approached with similar levels of caution around use cases that are sensitive to biases around human attributes; ergo, it has not been implemented.\n",
    "\n",
    "- Amirali Nassimi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af56448-39f7-4b81-b8ff-982e0e995500",
   "metadata": {},
   "source": [
    "# Load Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76283574-2bfa-4093-b20d-9a39b48b64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83aae24-a430-4457-93f6-47e3d266ab97",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e06f5d9-98d4-4dc3-b110-1d1d71fc380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-xl\"  # \n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244113b-bf8b-4761-8437-47ea4de98b41",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15538e6-059a-4d4e-841e-0c2e29e40f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "input_text = \"Once upon a time\"\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=200, num_return_sequences=1)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
